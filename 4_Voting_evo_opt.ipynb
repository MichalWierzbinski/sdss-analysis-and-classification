{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genetic optimization of XTree classifier for the SDSS data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T10:04:52.000642Z",
     "start_time": "2019-05-12T10:04:50.915321Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "import warnings\n",
    "import helpers\n",
    "from helpers import DataSet\n",
    "import matplotlib as mpl\n",
    "import os\n",
    "import random\n",
    "\n",
    "# Common imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# Imports for ML\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, BaggingClassifier, GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, PassiveAggressiveClassifier, RidgeClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, MaxAbsScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"results\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "\n",
    "# Helper functioins and structures\n",
    "# Ignore useless warnings (see SciPy issue #5998)\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")\n",
    "\n",
    "DATA_PATH = \"Skyserver_SQL2_27_2018 6_51_39 PM.csv\"\n",
    "RESULTS_FOLDER = \"results\"\n",
    "\n",
    "# We load the data. Those that have nothing to do with the features of the objects are ignored.\n",
    "sdss_data = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# We have a general look at the features\n",
    "sdss_data.head(3)\n",
    "\n",
    "print(sdss_data.columns.values)\n",
    "sdss_data.drop(['objid', 'run', 'rerun', 'camcol', 'field',\n",
    "                'specobjid', 'fiberid', 'mjd', 'plate'], axis=1, inplace=True)\n",
    "sdss_data.head(1)\n",
    "\n",
    "sdss_df_fe = sdss_data\n",
    "\n",
    "# Principal Component Analysis\n",
    "pca = PCA(n_components=3)\n",
    "ugriz = pca.fit_transform(sdss_df_fe[['u', 'g', 'r', 'i', 'z']])\n",
    "\n",
    "# update dataframe\n",
    "sdss_df_fe = pd.concat((sdss_df_fe, pd.DataFrame(ugriz)), axis=1)\n",
    "sdss_df_fe.rename({0: 'PCA_1', 1: 'PCA_2', 2: 'PCA_3'}, axis=1, inplace=True)\n",
    "sdss_df_fe.drop(['u', 'g', 'r', 'i', 'z'], axis=1, inplace=True)\n",
    "sdss_df_fe.head()\n",
    "\n",
    "X = sdss_data.drop(['class'], axis=1)\n",
    "y = sdss_data['class']\n",
    "\n",
    "class_names = [\"GALAXY\", \"QSO\", \"STAR\"]\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "X_test = std_scaler.fit_transform(X_test.astype(np.float64))\n",
    "X_train = std_scaler.fit_transform(X_train.astype(np.float64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T15:27:50.318638Z",
     "start_time": "2019-05-12T15:27:50.280074Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def prepare_clfs():\n",
    "    knn_clf = KNeighborsClassifier(n_neighbors=3,\n",
    "                                  weights='distance', \n",
    "                                  algorithm='auto',\n",
    "                                  leaf_size=23, \n",
    "                                  p=2,\n",
    "                                  metric='manhattan', \n",
    "                                  n_jobs=4)\n",
    "\n",
    "    lsvm_clf = LinearSVC(penalty='l2',\n",
    "                       loss='squared_hinge',\n",
    "                       dual=False,\n",
    "                       C=303919.53823132074,\n",
    "                       multi_class='ovr',\n",
    "                       fit_intercept=True,\n",
    "                       intercept_scaling=1.0,\n",
    "                       class_weight='balanced',\n",
    "                       verbose=False,\n",
    "                       max_iter=10000,\n",
    "                       random_state=42)\n",
    "    \n",
    "    nusvm_clf = NuSVC(nu=0.01743328822199991,\n",
    "                   kernel=\"rbf\",\n",
    "                   gamma=0.01743328822199991, \n",
    "                   degree=7,\n",
    "                   coef0=4.5203536563602496e-05, \n",
    "                   shrinking=True,\n",
    "                   probability=True,\n",
    "                   tol=0.001,\n",
    "                   cache_size=20, \n",
    "                   class_weight=\"balanced\",\n",
    "                   verbose=False,\n",
    "                   max_iter=100000,\n",
    "                   random_state=42)\n",
    "\n",
    "    rbf_svm_clf = SVC(kernel=\"rbf\",\n",
    "                      C=18329.8071083243,\n",
    "                      gamma=0.004281332398719387,\n",
    "                      degree=8,\n",
    "                      coef0=0.0007847599703514606,\n",
    "                      shrinking=True,\n",
    "                      probability=True,\n",
    "                      tol=0.001,\n",
    "                      cache_size=100,\n",
    "                      class_weight=None,\n",
    "                      verbose=False,\n",
    "                      max_iter=-1,\n",
    "                      random_state=42)\n",
    "\n",
    "    poly_svm_clf = SVC(kernel='poly',\n",
    "                 C=788.0462815669937,\n",
    "                 gamma=0.0004893900918477499, \n",
    "                 degree=4,\n",
    "                 coef0=22.122162910704503, \n",
    "                 shrinking=False,\n",
    "                 probability=True, \n",
    "                 tol=0.001, \n",
    "                 cache_size=50,\n",
    "                 class_weight=None, \n",
    "                 verbose=False, \n",
    "                 max_iter=100000, \n",
    "                 random_state=42)\n",
    "\n",
    "    tree_clf = DecisionTreeClassifier(criterion=\"entropy\",\n",
    "                                      splitter=\"best\",\n",
    "                                      max_depth=3,\n",
    "                                      min_weight_fraction_leaf=0.0014384498882876629,\n",
    "                                      max_leaf_nodes=9,\n",
    "                                      presort=True,\n",
    "                                      min_samples_split=6,\n",
    "                                      min_samples_leaf=4,\n",
    "                                      max_features=None,\n",
    "                                      random_state=42)\n",
    "\n",
    "    rnd_clf = RandomForestClassifier(n_estimators=100,\n",
    "                                     criterion=\"entropy\",\n",
    "                                     min_samples_split=4,\n",
    "                                     min_samples_leaf=2,\n",
    "                                     max_features=None,\n",
    "                                     bootstrap=True,\n",
    "                                     oob_score=True,\n",
    "                                     random_state=42)\n",
    "\n",
    "    log_clf = LogisticRegression(penalty='l1',\n",
    "                                 dual=False,\n",
    "                                 C=31.622776601683793,\n",
    "                                 fit_intercept=True,\n",
    "                                 intercept_scaling=0.5878016072274912,\n",
    "                                 class_weight='balanced',\n",
    "                                 solver='saga',\n",
    "                                 multi_class='multinomial',\n",
    "                                 warm_start=False,\n",
    "                                 n_jobs=4,\n",
    "                                 max_iter=1000,\n",
    "                                 random_state=42)\n",
    "\n",
    "    gb_clf = GradientBoostingClassifier(loss=\"deviance\",\n",
    "                                        learning_rate=0.18329807108324356,\n",
    "                                        n_estimators=83,\n",
    "                                        criterion=\"friedman_mse\",\n",
    "                                        min_samples_split=3,\n",
    "                                        min_samples_leaf=7,\n",
    "                                        max_depth=7,\n",
    "                                        random_state=42)\n",
    "\n",
    "    xgb_clf = XGBClassifier(eta=0.01778279410038923,\n",
    "                            gamma=0.01,\n",
    "                            max_depth=4,\n",
    "                            min_child_weight=0.03831186849557289,\n",
    "                            max_delta_step=0.35938136638046275,\n",
    "                            subsample=1.0,\n",
    "                            reg_lambda=5.994842503189409,\n",
    "                            alpha=1.7782794100389228e-08,\n",
    "                            colsample_bytree=0.9,\n",
    "                            objective=\"multi:softprob\",\n",
    "                            seed=42,\n",
    "                            n_estimators=4216,\n",
    "                            nthread=4)\n",
    "\n",
    "    bag_df_clf = BaggingClassifier(n_estimators=261,\n",
    "                                   max_samples=46,\n",
    "                                   max_features=6,\n",
    "                                   bootstrap=False,\n",
    "                                   bootstrap_features=False,\n",
    "                                   oob_score=False,\n",
    "                                   n_jobs=4,\n",
    "                                   random_state=42)\n",
    "\n",
    "    ada_clf = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=3),\n",
    "                                 n_estimators=825,\n",
    "                                 learning_rate=0.19573417814876617,\n",
    "                                 algorithm='SAMME',\n",
    "                                 random_state=42)\n",
    "\n",
    "    sgd_clf = SGDClassifier(loss='perceptron',\n",
    "                            penalty='l1',\n",
    "                            alpha=0.00510896977450693,\n",
    "                            l1_ratio=0.014677992676220698,\n",
    "                            fit_intercept=True,\n",
    "                            shuffle=True,\n",
    "                            epsilon=0.4216965034285822,\n",
    "                            n_jobs=4,\n",
    "                            random_state=42,\n",
    "                            learning_rate='optimal',\n",
    "                            eta0=0.2,\n",
    "                            power_t=0.014677992676220698,\n",
    "                            early_stopping=True,\n",
    "                            n_iter_no_change=5,\n",
    "                            class_weight=None,\n",
    "                            average=False)\n",
    "\n",
    "    mlp_clf = MLPClassifier(hidden_layer_sizes=(20, 20),\n",
    "                           activation='relu',\n",
    "                           solver='sgd', \n",
    "                           alpha=1e-05, \n",
    "                           batch_size=3, \n",
    "                           learning_rate='adaptive',\n",
    "                           learning_rate_init=0.1333521432163324, \n",
    "                           power_t=0.004216965034285823, \n",
    "                           max_iter=1000,\n",
    "                           random_state=42,\n",
    "                           momentum=0.1,\n",
    "                           nesterovs_momentum=True, \n",
    "                           early_stopping=True,\n",
    "                           beta_1=0.7, \n",
    "                           beta_2=0.4210900698456838, \n",
    "                           epsilon=1e-08,\n",
    "                           n_iter_no_change=5)\n",
    "\n",
    "    xtree_clf = ExtraTreesClassifier(n_estimators=2154,\n",
    "                                     criterion=\"gini\",\n",
    "                                     min_samples_split=2,\n",
    "                                     min_samples_leaf=1,\n",
    "                                     max_features=None,\n",
    "                                     bootstrap=False,\n",
    "                                     oob_score=False,\n",
    "                                     random_state=42)\n",
    "\n",
    "    pa_clf = PassiveAggressiveClassifier(loss='hinge',\n",
    "                                         shuffle=False,\n",
    "                                         n_jobs=4,\n",
    "                                         random_state=42,\n",
    "                                         early_stopping=True,\n",
    "                                         warm_start=False,\n",
    "                                         class_weight='balanced',\n",
    "                                         average=False)\n",
    "\n",
    "    r_clf = RidgeClassifier(alpha=0.11006941712522103,\n",
    "                            fit_intercept=False,\n",
    "                            normalize=False,\n",
    "                            copy_X=True,\n",
    "                            max_iter=3000,\n",
    "                            class_weight=None,\n",
    "                            solver='cholesky',\n",
    "                            random_state=42)\n",
    "\n",
    "    nb_clf = GaussianNB(var_smoothing=3.727593720314938e-11)\n",
    "\n",
    "    lda_clf = LinearDiscriminantAnalysis(\n",
    "        solver=\"svd\", shrinkage=None, n_components=None, store_covariance=False)\n",
    "\n",
    "    qda_clf = QuadraticDiscriminantAnalysis(\n",
    "        reg_param=2.1544346900318867e-07, store_covariance=False)\n",
    "\n",
    "    clf_names = [\"KNN\",\n",
    "                 \"LinearSVM\",\n",
    "                 \"NuSVC\",\n",
    "                 \"RbfKernelSVM\",\n",
    "                 \"PolyKernelSVM\",\n",
    "                 \"DecisionTreeClassifier\",\n",
    "                 \"RandomForestClassifier\",\n",
    "                 \"LogisticRegression\",\n",
    "                 \"GradientBoostingClassifier\",\n",
    "                 \"XGBClassifier\",\n",
    "                 \"BaggingClassifier\",\n",
    "                 \"AdaBoostClassifier\",\n",
    "                 \"SGDClassifier\",\n",
    "                 \"MLPClassifier\",\n",
    "                 \"ExtraTreesClassifier\",\n",
    "                 \"PassiveAggressiveClassifier\",\n",
    "                 \"RidgeClassifier\",\n",
    "                 \"GaussianNB\",\n",
    "                 \"LinearDiscriminantAnalysis\",\n",
    "                 \"QuadraticDiscriminantAnalysis\"\n",
    "                 ]\n",
    "\n",
    "    clfs = [knn_clf,\n",
    "            lsvm_clf,\n",
    "            nusvm_clf,\n",
    "            rbf_svm_clf,\n",
    "            poly_svm_clf,\n",
    "            tree_clf,\n",
    "            rnd_clf,\n",
    "            log_clf,\n",
    "            gb_clf,\n",
    "            xgb_clf,\n",
    "            bag_df_clf,\n",
    "            ada_clf,\n",
    "            sgd_clf,\n",
    "            mlp_clf,\n",
    "            xtree_clf,\n",
    "            pa_clf,\n",
    "            r_clf,\n",
    "            nb_clf,\n",
    "            lda_clf,\n",
    "            qda_clf\n",
    "            ]\n",
    "\n",
    "    return list(zip(clf_names, clfs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T15:27:50.931171Z",
     "start_time": "2019-05-12T15:27:50.919849Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_random_clf_sets(clfs, num=5):\n",
    "    clf_sets = []\n",
    "\n",
    "    for i in range(0, num):\n",
    "        clf_num = random.randint(3, len(clfs))\n",
    "        clf_list = random.sample(clfs, clf_num)\n",
    "        clf_sets.append(clf_list)\n",
    "    \n",
    "    return clf_sets\n",
    "\n",
    "clf_choices = get_random_clf_sets(prepare_clfs(), 230)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T15:27:51.294118Z",
     "start_time": "2019-05-12T15:27:51.276064Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def print_choices(clf_choices):\n",
    "    i = 0\n",
    "    for clf_tuple in clf_choices:\n",
    "        print(\"=======Choice \" + str(i) + \"=======\")\n",
    "        clfnames = []\n",
    "        for clf in clf_tuple:\n",
    "            clfnames.append(clf[0])\n",
    "        i = i + 1\n",
    "        print(clfnames)\n",
    "        \n",
    "        \n",
    "print_choices(clf_choices)\n",
    "\n",
    "def print_choices_single(choice, i=None):\n",
    "    if (i is None): \n",
    "        print(\"=======Choice=======\")\n",
    "    else:\n",
    "        print(\"=======Choice \" + str(i) + \"=======\")\n",
    "    clfnames = []\n",
    "    for clf in choice:\n",
    "        clfnames.append(clf[0])\n",
    "    print(clfnames)\n",
    "    \n",
    "print_choices_single(clf_choices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T16:49:16.409739Z",
     "start_time": "2019-05-12T16:07:41.151678Z"
    }
   },
   "outputs": [],
   "source": [
    "from evolutionary_search import EvolutionaryAlgorithmSearchCV\n",
    "\n",
    "for clf_choice in clf_choices:\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        result = # todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T10:59:32.004965Z",
     "start_time": "2019-05-11T10:58:35.027335Z"
    }
   },
   "outputs": [],
   "source": [
    "best_indiv = VotingClassifier() # todo\n",
    "\n",
    "clf_names = [\"ExtraTreesClassifier\"]\n",
    "class_names = [\"GALAXY\", \"QSO\", \"STAR\"]\n",
    "\n",
    "clfs = [best_indiv]\n",
    "data_sets = []\n",
    "std_scaled_set = DataSet(\"Standard Scaled\", X_train, y_train, X_test, y_test)\n",
    "data_sets.append(std_scaled_set)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    helpers.learning_loop_for_sets(clfs, clf_names, class_names, data_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python3 (deep)",
   "language": "python",
   "name": "deep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
